{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b6c77b-3f7f-48a3-a2b6-e3e1c22db06d",
   "metadata": {},
   "source": [
    "## Bag Of Words Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07833fbe-b749-4378-a00b-046495f7cce7",
   "metadata": {},
   "source": [
    "##### Bag of Words (BoW) is a Natural Language Processing strategy for converting a text document into numbers that can be used by a computer program. This method involves converting text into a vector based on the frequency of words in the text, without considering the order or context of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64440f0-71e5-4fb7-a32e-4015715e794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71f87505-014e-451a-b92e-cc329eb4eff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3398233337.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    text =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "text = \n",
    "    \"\"\"The quick brown fox jumped over the lazy dog.\n",
    "    She sells seashells by the seashore.\n",
    "    Peter Piper picked a peck of pickled peppers.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb176496-b328-4bf8-9bdb-84128dc45647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.sent_tokenize(text) \n",
    "for i in range(len(dataset)): \n",
    "    dataset[i] = dataset[i].lower() \n",
    "    dataset[i] = re.sub(r'\\W', ' ', dataset[i]) \n",
    "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60066b2f-a272-4cd2-a4a9-7c2f2e2b46c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the quick brown fox jumped over the lazy dog ',\n",
       " 'she sells seashells by the seashore ',\n",
       " 'peter piper picked a peck of pickled peppers ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab37da47-c19c-465f-a07f-f3912e847b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {} \n",
    "for data in dataset: \n",
    "    words = nltk.word_tokenize(data) \n",
    "    for word in words: \n",
    "        if word not in word2count.keys(): \n",
    "            word2count[word] = 1\n",
    "        else: \n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa64471d-3377-4ab1-9e19-24f05b1bf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import heapq \n",
    "freq_words = heapq.nlargest(30, word2count, key=word2count.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a3b6b2e-5d63-4f5e-8603-8382a0554b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumped',\n",
       " 'over',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'seashells',\n",
       " 'by',\n",
       " 'seashore',\n",
       " 'peter',\n",
       " 'piper',\n",
       " 'picked',\n",
       " 'a',\n",
       " 'peck',\n",
       " 'of',\n",
       " 'pickled',\n",
       " 'peppers']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee304f4b-8c52-459e-aaf8-9e5fc75a267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] \n",
    "for data in dataset: \n",
    "    vector = [] \n",
    "    for word in freq_words: \n",
    "        if word in nltk.word_tokenize(data): \n",
    "            vector.append(1) \n",
    "        else: \n",
    "            vector.append(0) \n",
    "    X.append(vector) \n",
    "X = np.asarray(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a198d580-4e81-4f9b-ac82-5699cdb2b6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766f1da-d57f-4dff-9630-089760938237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
